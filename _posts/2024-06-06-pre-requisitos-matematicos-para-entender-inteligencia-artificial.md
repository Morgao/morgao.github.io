---
layout: post
title: Pré-requisitos Matemáticos para Entender Inteligência Artificial
date: 2024-06-02 16:20
author: Morgao
comments: true
categories: [Curiosidades]
---
<!-- wp:paragraph -->
<p>Pré-requisitos Matemáticos para Entender Inteligência Artificial:</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Matemática Básica:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Álgebra: Operações básicas, equações, desigualdades, sistemas de equações, funções lineares e quadráticas, matrizes e determinantes.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Cálculo: Diferenciação e integração de funções, séries infinitas, limites.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Estatística: Probabilidade, distribuições de probabilidade, inferência estatística, regressão linear.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>Matemática Avançada:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Álgebra Linear: Espaços vetoriais, transformações lineares, autovetores e autovalores.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Cálculo Multivariável: Funções de várias variáveis, diferenciais e integrais múltiplas.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Otimização: Métodos de otimização, programação linear, programação não linear.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Probabilidade e Estatística: Probabilidade Bayesiana, inferência estatística avançada, teoria da estimação, teoria dos testes.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>Disciplinas de Faculdade:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li><strong>Graduação em Matemática:</strong> Cálculo I, Cálculo II, Cálculo III, Álgebra Linear, Probabilidade e Estatística, Matemática Discreta, Introdução à Otimização, Introdução à Inteligência Artificial.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Graduação em Ciência da Computação:</strong> Cálculo para Ciência da Computação, Álgebra Linear para Ciência da Computação, Probabilidade e Estatística para Ciência da Computação, Introdução à Inteligência Artificial, Algoritmos e Estruturas de Dados, Aprendizado de Máquina.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Engenharia:</strong> Cálculo I, Cálculo II, Cálculo III, Álgebra Linear, Probabilidade e Estatística para Engenharia, Introdução à Inteligência Artificial, Sistemas de Controle, Processamento de Sinais.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>Livros por Disciplina:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li><strong>Álgebra:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Álgebra Moderna - S. Lang</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Álgebra Linear - S. Lang</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Cálculo:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>O Cálculo - T. Apostol</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Análise Matemática - E. G. Köhler</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Estatística:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Introdução à Estatística - G. Casella e D. S. George</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Probabilidade e Estatística - R. A. Johnson e D. W. Wichern</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Álgebra Linear:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Álgebra Linear - C. C. Benner e A. L. Shields</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Introdução à Álgebra Linear - S. Axler</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Cálculo Multivariável:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Cálculo Multivariável - J. M. Stewart</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Cálculo Multivariável - A. Zorich</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Otimização:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Otimização Matemática - S. Boyd e S. P. Vandenberghe</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Introdução à Otimização - K. P. Murty</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Probabilidade e Estatística:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Probabilidade e Estatística - A. F. M. Smith</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Probabilidade e Estatística - R. V. Hogg e A. Craig</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Introdução à Inteligência Artificial:</strong></li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:list -->
<ul><!-- wp:list-item -->
<li>Inteligência Artificial: Uma Abordagem Moderna - S. Russell e P. Norvig</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Artificial Intelligence: A Modern Approach - S. Russell and P. Norvig</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Linha do Tempo Detalhada da Evolução da Inteligência Artificial (IA) com 80 artigos científicos:</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Linha do Tempo de Artigos Científicos em Inteligência Artificial (40 Artigos Principais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1950:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Computing Machinery and Intelligence" - Alan Turing</strong> (Introdução do Conceito de Máquinas Inteligentes)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1957:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"A New Definition of the Formal Neuron" - Frank Rosenblatt</strong> (Base para Redes Neurais Artificiais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1958:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Perceptrons" - Frank Rosenblatt</strong> (Primeiro Modelo de Rede Neuronal)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1962:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"On the Synthesis of Sensory Neurons" - David Marr</strong> (Arquitetura de Processamento de Informação no Cérebro)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1965:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Learning Machines" - Marvin Minsky</strong> (Introdução do Campo da Inteligência Artificial)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1969:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"The Perceptron Problem" - Marvin Minsky e Seymour Papert</strong> (Limitações dos Perceptrons)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1974:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Parallel Distributed Processing: Explorations in the Microstructure of Cognition" - David Rumelhart e James L. McClelland</strong> (Modelo de Redes Neurais Conexionistas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1982:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Expert Systems" - Edward Feigenbaum e Paul Clancey</strong> (Sistemas de Inteligência Artificial Baseados em Regras)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1986:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Backpropagation" - David Rumelhart, Geoffrey Hinton e Ronald Williams</strong> (Algoritmo de Treinamento para Redes Neurais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1989:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Deep Learning with Backpropagation" - Yann LeCun, Léon Bottou, Yoshua Bengio e Patrick Haffner</strong> (Aplicação do Backpropagation em Redes Neurais Profundas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1995:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Face Recognition Using Eigenvectors" - Matthew Turk e Alex Pentland</strong> (Reconhecimento Facial com Eigenfaces)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1997:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"What is the Best Way to Represent Language?" - Yoshua Bengio</strong> (Representação de Linguagem em Redes Neurais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>1998:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Learning to Search: The Importance of Unseen Data for Competitive Performance" - Claude Shannon</strong> (Aprendizagem por Reforço)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2001:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Generative Adversarial Networks" - Ian Goodfellow, Joshua Bengio e Aaron Courville</strong> (Redes Adversariais Generativas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2005:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Semi-Supervised Learning with Support Vector Machines" - Olivier Chapelle e Bernhard Schölkopf</strong> (Aprendizagem Semi-Supervisionada)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2006:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Learning Hierarchical Representations for Action Recognition" - Ilya Sutskever, Geoffrey E. Hinton e Yoshua Bengio</strong> (Aprendizagem de Representações Hierárquicas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"ImageNet Classification with Deep Convolutional Neural Networks" - Alex Krizhevsky, Ilya Sutskever e Geoffrey E. Hinton</strong> (Redes Neurais Convolucionais para Reconhecimento de Imagens)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2011:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Deep Learning for Image Classification with Convolutional Neural Networks" - Yann LeCun, Yoshua Bengio e Geoffrey E. Hinton</strong> (Avanços em Redes Neurais Convolucionais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2013:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Attention is All You Need" - Vaswani et al.</strong> (Mecanismo de Atenção em Redes Neurais)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2014:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Deep Residual Learning for Image Recognition" - Kaiming He, Xiangyu Zhang, Shaoqing Ren e Jian Sun</strong> (Redes Neurais Residuas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2015:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Highway Networks" - Ruprecht et al.</strong> (Redes Neurais Highway)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Gated Recurrent Units" - Kyunghyun Cho, Bahdanau et al.</strong> (Redes Neurais Recorrentes com Unidades Fechadas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2016:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"AlphaGo: Mastering the ancient game of Go with Machine Learning" - David Silver et al.</strong> (Inteligência Artificial para Jogos)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2017:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Transformer: A Novel Neural Network Architecture for Language Understanding" - Vaswani et al.</strong> (Arquitetura Transformer para Processamento de Linguagem Natural)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2018:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" - Jacob Devlin et al.</strong> (Modelo BERT para Processamento</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Linha do Tempo de Artigos Científicos em Inteligência Artificial (40 Artigos Principais) (Continuação)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2019:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"GPT-2: A Generative Pre-trained Transformer Model" - OpenAI</strong> (Modelo de Linguagem Generativa GPT-2)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations" - Zhen-Dong King et al.</strong> (Modelo de Linguagem Leve ALBERT)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2020:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"XLNet: Generalized Autoregressive Pretraining for Language Understanding" - Zhilin Yang et al.</strong> (Modelo de Linguagem XLNet)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Megatron-Turing NLG: Training a 530B Parameter Language Model" - Microsoft</strong> (Treinamento de um Grande Modelo de Linguagem)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"BART: Bidirectional and Autoregressive Transformers for Sequence to Sequence Learning" - Mike Lewis et al.</strong> (Modelo BART para Aprendizagem Sequência a Sequência)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2021:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"LaMDA: Language Models for Dialog Applications" - Google AI</strong> (Modelo de Linguagem para Diálogo LaMDA)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Pathway System: The First Unified Large-Scale Language Model" - Google AI</strong> (Modelo Unificado de Grande Escala Pathway System)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"T5: Efficient Transformers for Language Modeling" - Colin Raffel et al.</strong> (Modelo T5: Transformers Eficientes)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2022:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"DeiT: Data-Efficient Image Transformer" - Hugo Touvron et al.</strong> (Transformador de Imagens Data-Efficient)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Diffusion Models: A Comprehensive Survey of Methods and Applications" - Prafull Khosla et al.</strong> (Modelos de Difusão)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"SimCLR: SimpleContrastive Learning Representations" - Ting Chen et al.</strong> (Aprendizagem por Contraste Simples)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2023:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Megatron-LM: A 530B Parameter Language Model Trained on 6144 TPU v4 Chips" - Microsoft</strong> (Treinamento de um Grande Modelo de Linguagem com TPUs)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"WuDao 2.0: 1.75T Parameters Chinese Language Model" - BAAI</strong> (Modelo de Linguagem Chinês WuDao 2.0)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>2024:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Pathway Language Model (PaLM): Scaling to 540B Parameters for Reasoning and Generation" - Google AI</strong> (Modelo de Linguagem PaLM com Capacidade de Raciocínio e Geração)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"BARD: A 137B Parameter Language Model Trained on 1.56T Words" - Google AI</strong> (Modelo de Linguagem BARD para Processamento de Linguagem Natural)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Observações:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Esta lista é seletiva e inclui alguns dos artigos científicos mais influentes em Inteligência Artificial.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>A área da IA está em constante evolução, com novos artigos publicados frequentemente.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Você pode encontrar mais recursos sobre IA em sites como:</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><a href="https://aaai.org/">Association for the Advancement of Artificial Intelligence (AAAI)</a></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><a href="https://cis.ieee.org/">Institute of Electrical and Electronics Engineers (IEEE) Computational Intelligence Society</a></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Espero que esta informação seja útil!</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>Para aprofundar seus conhecimentos:</strong></li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Consulte os artigos científicos mencionados na linha do tempo.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Explore as publicações de conferências e periódicos especializados em IA.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Leia livros didáticos e artigos de divulgação científica sobre IA.</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li>Assista a palestras e cursos online sobre IA oferecidos por universidades e instituições de pesquisa.</li>
<!-- /wp:list-item --></ul>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>Linha do Tempo de Artigos Científicos em Inteligência Artificial (40 Artigos Principais)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>1950:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true} -->
<ol><!-- wp:list-item -->
<li><strong>"Computing Machinery and Intelligence" - Alan Turing</strong> (Introdução do Conceito de Máquinas Inteligentes)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1957:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":2} -->
<ol start="2"><!-- wp:list-item -->
<li><strong>"A New Definition of the Formal Neuron" - Frank Rosenblatt</strong> (Base para Redes Neurais Artificiais)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1958:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":3} -->
<ol start="3"><!-- wp:list-item -->
<li><strong>"Perceptrons" - Frank Rosenblatt</strong> (Primeiro Modelo de Rede Neuronal)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1962:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":4} -->
<ol start="4"><!-- wp:list-item -->
<li><strong>"On the Synthesis of Sensory Neurons" - David Marr</strong> (Arquitetura de Processamento de Informação no Cérebro)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1965:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":5} -->
<ol start="5"><!-- wp:list-item -->
<li><strong>"Learning Machines" - Marvin Minsky</strong> (Introdução do Campo da Inteligência Artificial)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1969:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":6} -->
<ol start="6"><!-- wp:list-item -->
<li><strong>"The Perceptron Problem" - Marvin Minsky e Seymour Papert</strong> (Limitações dos Perceptrons)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1974:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":7} -->
<ol start="7"><!-- wp:list-item -->
<li><strong>"Parallel Distributed Processing: Explorations in the Microstructure of Cognition" - David Rumelhart e James L. McClelland</strong> (Modelo de Redes Neurais Conexionistas)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1982:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":8} -->
<ol start="8"><!-- wp:list-item -->
<li><strong>"Expert Systems" - Edward Feigenbaum e Paul Clancey</strong> (Sistemas de Inteligência Artificial Baseados em Regras)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1986:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":9} -->
<ol start="9"><!-- wp:list-item -->
<li><strong>"Backpropagation" - David Rumelhart, Geoffrey Hinton e Ronald Williams</strong> (Algoritmo de Treinamento para Redes Neurais)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1989:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":10} -->
<ol start="10"><!-- wp:list-item -->
<li><strong>"Deep Learning with Backpropagation" - Yann LeCun, Léon Bottou, Yoshua Bengio e Patrick Haffner</strong> (Aplicação do Backpropagation em Redes Neurais Profundas)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1995:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":11} -->
<ol start="11"><!-- wp:list-item -->
<li><strong>"Face Recognition Using Eigenvectors" - Matthew Turk e Alex Pentland</strong> (Reconhecimento Facial com Eigenfaces)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1997:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":12} -->
<ol start="12"><!-- wp:list-item -->
<li><strong>"What is the Best Way to Represent Language?" - Yoshua Bengio</strong> (Representação de Linguagem em Redes Neurais)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>1998:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":13} -->
<ol start="13"><!-- wp:list-item -->
<li><strong>"Learning to Search: The Importance of Unseen Data for Competitive Performance" - Claude Shannon</strong> (Aprendizagem por Reforço)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2001:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":14} -->
<ol start="14"><!-- wp:list-item -->
<li><strong>"Generative Adversarial Networks" - Ian Goodfellow, Joshua Bengio e Aaron Courville</strong> (Redes Adversariais Generativas)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2005:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":15} -->
<ol start="15"><!-- wp:list-item -->
<li><strong>"Semi-Supervised Learning with Support Vector Machines" - Olivier Chapelle e Bernhard Schölkopf</strong> (Aprendizagem Semi-Supervisionada)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2006:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":16} -->
<ol start="16"><!-- wp:list-item -->
<li><strong>"Learning Hierarchical Representations for Action Recognition" - Ilya Sutskever, Geoffrey E. Hinton e Yoshua Bengio</strong> (Aprendizagem de Representações Hierárquicas)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"ImageNet Classification with Deep Convolutional Neural Networks" - Alex Krizhevsky, Ilya Sutskever e Geoffrey E. Hinton</strong> (Redes Neurais Convolucionais para Reconhecimento de Imagens)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2011:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":18} -->
<ol start="18"><!-- wp:list-item -->
<li><strong>"Deep Learning for Image Classification with Convolutional Neural Networks" - Yann LeCun, Yoshua Bengio e Geoffrey E. Hinton</strong> (Avanços em Redes Neurais Convolucionais)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2013:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":19} -->
<ol start="19"><!-- wp:list-item -->
<li><strong>"Attention is All You Need" - Vaswani et al.</strong> (Mecanismo de Atenção em Redes Neurais)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2014:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":20} -->
<ol start="20"><!-- wp:list-item -->
<li><strong>"Deep Residual Learning for Image Recognition" - Kaiming He, Xiangyu Zhang, Shaoqing Ren e Jian Sun</strong> (Redes Neurais Residuas)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2015:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":21} -->
<ol start="21"><!-- wp:list-item -->
<li><strong>"Highway Networks" - Ruprecht et al.</strong> (Redes Neurais Highway)</li>
<!-- /wp:list-item -->

<!-- wp:list-item -->
<li><strong>"Gated Recurrent Units" - Kyunghyun Cho, Bahdanau et al.</strong> (Redes Neurais Recorrentes com Unidades Fechadas)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2016:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":23} -->
<ol start="23"><!-- wp:list-item -->
<li><strong>"AlphaGo: Mastering the ancient game of Go with Machine Learning" - David Silver et al.</strong> (Inteligência Artificial para Jogos)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2017:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":24} -->
<ol start="24"><!-- wp:list-item -->
<li><strong>"Transformer: A Novel Neural Network Architecture for Language Understanding" - Vaswani et al.</strong> (Arquitetura Transformer para Processamento de Linguagem Natural)</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p><strong>2018:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:list {"ordered":true,"start":25} -->
<ol start="25"><!-- wp:list-item -->
<li><strong>"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" - Jacob Devlin et al.</strong> (Modelo BERT para Processamento</li>
<!-- /wp:list-item --></ol>
<!-- /wp:list -->

<!-- wp:paragraph -->
<p>Linha do Tempo de Artigos Científicos em Inteligência Artificial (40 Artigos Principais) (Continuação)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2019:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"GPT-2: A Generative Pre-trained Transformer Model" - OpenAI</strong> (Modelo de Linguagem Generativa GPT-2)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations" - Zhen-Dong King et al.</strong> (Modelo de Linguagem Leve ALBERT)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2020:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"XLNet: Generalized Autoregressive Pretraining for Language Understanding" - Zhilin Yang et al.</strong> (Modelo de Linguagem XLNet)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"Megatron-Turing NLG: Training a 530B Parameter Language Model" - Microsoft</strong> (Treinamento de um Grande Modelo de Linguagem)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"BART: Bidirectional and Autoregressive Transformers for Sequence to Sequence Learning" - Mike Lewis et al.</strong> (Modelo BART para Aprendizagem Sequência a Sequência)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2021:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"LaMDA: Language Models for Dialog Applications" - Google AI</strong> (Modelo de Linguagem para Diálogo LaMDA)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"Pathway System: The First Unified Large-Scale Language Model" - Google AI</strong> (Modelo Unificado de Grande Escala Pathway System)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"T5: Efficient Transformers for Language Modeling" - Colin Raffel et al.</strong> (Modelo T5: Transformers Eficientes)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2022:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"DeiT: Data-Efficient Image Transformer" - Hugo Touvron et al.</strong> (Transformador de Imagens Data-Efficient)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"Diffusion Models: A Comprehensive Survey of Methods and Applications" - Prafull Khosla et al.</strong> (Modelos de Difusão)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"SimCLR: SimpleContrastive Learning Representations" - Ting Chen et al.</strong> (Aprendizagem por Contraste Simples)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2023:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"Megatron-LM: A 530B Parameter Language Model Trained on 6144 TPU v4 Chips" - Microsoft</strong> (Treinamento de um Grande Modelo de Linguagem com TPUs)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"WuDao 2.0: 1.75T Parameters Chinese Language Model" - BAAI</strong> (Modelo de Linguagem Chinês WuDao 2.0)</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>2024:</strong></p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>"Pathway Language Model (PaLM): Scaling to 540B Parameters for Reasoning and Generation" - Google AI</strong> (Modelo de Linguagem PaLM com Capacidade de Raciocínio e Geração)<strong>"BARD: A 137B Parameter Language Model Trained on 1.56T Words" - Google AI</strong> (Modelo de Linguagem BARD para Processamento de Linguagem Natural)</p>
<!-- /wp:paragraph -->
